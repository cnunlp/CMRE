# Chinese model configuration.

bert_base_chinese {
  # Edit this
  data_dir = ./data

  # Computation limits.
  max_top_antecedents = 15                # 50
  max_training_sentences = 11             # 11
  top_span_ratio = 0.8                    # 0.4  0.6  0.8(2e-5)
  max_num_speakers = 20
  max_segment_len = 40                    # 128

  # Learning
  bert_learning_rate = 1e-05
  task_learning_rate = 2e-4             # 0.0002   2e-4   2e-5   type change(-6)
  span_type_learning_rate = 0.01
  adam_eps = 1e-6
  dropout_rate = 0.3

  # Task choice
  num_docs = 6794
  num_epochs = 15
  do_train = true
  do_eval = true
  do_test = false
  do_one_example_test = true
  eval_frequency = 6793
  report_frequency = 1000

  # Model hyperparameters.
  genres = ["bc", "bn", "mz", "nw", "tc", "wb"]
  coref_depth = 1                      # 2
  ffnn_size = 2000                     # 2000
  feature_size = 20
  max_span_width = 15                 # 30
  use_metadata = false
  use_features = true
  use_segment_distance = false        # true
  model_heads = true
  fine_grained = true
  use_prior = true
  single_example = true
  # use_salience = false
  num_salience = 65
  static_mention_scores = false
  use_span_type = true          # dev
  add_span_pair_context = false

  # file path
  train_path = ${data_dir}/train_data.jsonlines
  eval_path = ${data_dir}/dev_data.jsonlines #测试的时候可以用验证的函数，注意修改数据集
  test_path = ${data_dir}/test_metaphor_type_add_v.jsonlines #保留测试的结果


  test_output_path = ${data_dir}/test_result.jsonlines
  online_output_path = ${data_dir}/online_test_result.jsonlines
  loss_write_path = ${data_dir}/test_loss.jsonlines

  model_save_path = ./metaphor_model/FULL


  #----------bert-wwm
  pretrained_model = ./src/chinese_bert_wwm_ext/
  vocab_file = ./src/chinese_bert_wwm_ext/vocab.txt
  bert_config_file = ./src/chinese_bert_wwm_ext/config.json

}
